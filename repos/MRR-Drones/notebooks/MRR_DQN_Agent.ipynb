{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(0)\n",
    "import time\n",
    "import numpy as np\n",
    "import airsim\n",
    "import config\n",
    "\n",
    "clockspeed = 1\n",
    "timeslice = 0.5 / clockspeed\n",
    "goalY = 57\n",
    "outY = -0.5\n",
    "floorZ = 1.18\n",
    "goals = [7, 17, 27.5, 45, goalY]\n",
    "speed_limit = 0.2\n",
    "ACTION = ['00', '+x', '+y', '+z', '-x', '-y', '-z']\n",
    "\n",
    "\n",
    "class Env:\n",
    "    def __init__(self):\n",
    "        # connect to the AirSim simulator\n",
    "        self.client = airsim.MultirotorClient()\n",
    "        self.client.confirmConnection()\n",
    "        self.action_size = 3\n",
    "        self.level = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.level = 0\n",
    "        self.client.reset()\n",
    "        self.client.enableApiControl(True)\n",
    "        self.client.armDisarm(True)\n",
    "\n",
    "        # my takeoff\n",
    "        self.client.simPause(False)\n",
    "        self.client.moveByVelocityAsync(0, 0, -1, 2 * timeslice).join()\n",
    "        self.client.moveByVelocityAsync(0, 0, 0, 0.1 * timeslice).join()\n",
    "        self.client.hoverAsync().join()\n",
    "        self.client.simPause(True)\n",
    "        quad_vel = self.client.getMultirotorState().kinematics_estimated.linear_velocity\n",
    "        responses = self.client.simGetImages(\n",
    "            [airsim.ImageRequest(1, airsim.ImageType.DepthVis, True)])\n",
    "        quad_vel = np.array([quad_vel.x_val, quad_vel.y_val, quad_vel.z_val])\n",
    "        observation = [responses, quad_vel]\n",
    "        return observation\n",
    "\n",
    "    def step(self, quad_offset):\n",
    "        # move with given velocity\n",
    "        quad_offset = [float(i) for i in quad_offset]\n",
    "        # quad_vel = self.client.getMultirotorState().kinematics_estimated.linear_velocity\n",
    "        self.client.simPause(False)\n",
    "\n",
    "        has_collided = False\n",
    "        landed = False\n",
    "        self.client.moveByVelocityAsync(\n",
    "            quad_offset[0], quad_offset[1], quad_offset[2], timeslice)\n",
    "        # self.client.moveByVelocityAsync(quad_vel.x_val+quad_offset[0], quad_vel.y_val+quad_offset[1], quad_vel.z_val+quad_offset[2], timeslice)\n",
    "        collision_count = 0\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < timeslice:\n",
    "            # get quadrotor states\n",
    "            quad_pos = self.client.getMultirotorState().kinematics_estimated.position\n",
    "            quad_vel = self.client.getMultirotorState().kinematics_estimated.linear_velocity\n",
    "\n",
    "            # decide whether collision occured\n",
    "            collided = self.client.simGetCollisionInfo().has_collided\n",
    "            # landed = quad_pos.y_val > 10 and self.client.getMultirotorState().landed_state == airsim.LandedState.Landed\n",
    "            # landed = landed or (quad_pos.y_val > 10 and quad_vel.x_val == 0 and quad_vel.y_val == 0 and quad_vel.z_val == 0)\n",
    "            landed = (quad_vel.x_val == 0 and quad_vel.y_val ==\n",
    "                      0 and quad_vel.z_val == 0)\n",
    "            landed = landed or quad_pos.z_val > floorZ\n",
    "            collision = collided or landed\n",
    "            if collision:\n",
    "                collision_count += 1\n",
    "            if collision_count > 10:\n",
    "                has_collided = True\n",
    "                break\n",
    "        self.client.simPause(True)\n",
    "\n",
    "        # observe with depth camera\n",
    "        responses = self.client.simGetImages(\n",
    "            [airsim.ImageRequest(1, airsim.ImageType.DepthVis, True)])\n",
    "\n",
    "        # get quadrotor states\n",
    "        quad_pos = self.client.getMultirotorState().kinematics_estimated.position\n",
    "        quad_vel = self.client.getMultirotorState().kinematics_estimated.linear_velocity\n",
    "\n",
    "        # decide whether done\n",
    "        dead = has_collided or quad_pos.y_val <= outY\n",
    "        done = dead or quad_pos.y_val >= goalY\n",
    "\n",
    "        # compute reward\n",
    "        reward = self.compute_reward(quad_pos, quad_vel, dead)\n",
    "\n",
    "        # log info\n",
    "        info = {}\n",
    "        info['Y'] = quad_pos.y_val\n",
    "        info['level'] = self.level\n",
    "        if landed:\n",
    "            info['status'] = 'landed'\n",
    "        elif has_collided:\n",
    "            info['status'] = 'collision'\n",
    "        elif quad_pos.y_val <= outY:\n",
    "            info['status'] = 'out'\n",
    "        elif quad_pos.y_val >= goalY:\n",
    "            info['status'] = 'goal'\n",
    "        else:\n",
    "            info['status'] = 'going'\n",
    "        quad_vel = np.array([quad_vel.x_val, quad_vel.y_val, quad_vel.z_val])\n",
    "        observation = [responses, quad_vel]\n",
    "        return observation, reward, done, info\n",
    "\n",
    "    def compute_reward(self, quad_pos, quad_vel, dead):\n",
    "        vel = np.array([quad_vel.x_val, quad_vel.y_val,\n",
    "                       quad_vel.z_val], dtype=np.float)\n",
    "        speed = np.linalg.norm(vel)\n",
    "        if dead:\n",
    "            reward = config.reward['dead']\n",
    "        elif quad_pos.y_val >= goals[self.level]:\n",
    "            self.level += 1\n",
    "            # reward = config.reward['forward'] * (1 + self.level / len(goals))\n",
    "            reward = config.reward['goal'] * (1 + self.level / len(goals))\n",
    "        elif speed < speed_limit:\n",
    "            reward = config.reward['slow']\n",
    "        else:\n",
    "            reward = float(vel[1]) * 0.1\n",
    "        # elif vel[1] > 0:\n",
    "        #     reward = config.reward['forward'] * (1 + self.level / len(goals))\n",
    "        # else:\n",
    "        #     reward = config.reward['normal']\n",
    "        return reward\n",
    "\n",
    "    def disconnect(self):\n",
    "        self.client.enableApiControl(False)\n",
    "        self.client.armDisarm(False)\n",
    "        print('Disconnected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.8.18 \n",
      "NumPy: 1.24.3\n",
      "gym: 0.26.2\n",
      "TensorFlow: 2.13.0\n",
      "Keras-rl2: 1.0.5\n"
     ]
    }
   ],
   "source": [
    "# env: gym37\n",
    "import sys # 3.7.16\n",
    "import random\n",
    "import numpy as np # 1.21.6\n",
    "import gym # 0.25.2\n",
    "import tensorflow # 2.10.0\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam    \n",
    "import rl # keras-rl2==1.0.5\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "print(\"Python: \" + sys.version[0:7])\n",
    "print(\"NumPy: \" + np.__version__)\n",
    "print(\"gym: \" + gym.__version__)\n",
    "print(\"TensorFlow: \" + tensorflow.__version__)\n",
    "print(\"Keras-rl2: 1.0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'AsyncIOLoop' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m, in \u001b[0;36mEnv.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# connect to the AirSim simulator\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mairsim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultirotorClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mconfirmConnection()\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages\\airsim\\client.py:1119\u001b[0m, in \u001b[0;36mMultirotorClient.__init__\u001b[1;34m(self, ip, port, timeout_value)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ip \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, port \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m41451\u001b[39m, timeout_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3600\u001b[39m):\n\u001b[1;32m-> 1119\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMultirotorClient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages\\airsim\\client.py:17\u001b[0m, in \u001b[0;36mVehicleClient.__init__\u001b[1;34m(self, ip, port, timeout_value)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (ip \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     16\u001b[0m     ip \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m127.0.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mmsgpackrpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsgpackrpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAddress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpack_encoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_encoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages\\msgpackrpc\\client.py:15\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, address, timeout, loop, builder, reconnect_limit, pack_encoding, unpack_encoding)\u001b[0m\n\u001b[0;32m     12\u001b[0m session\u001b[38;5;241m.\u001b[39mSession\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, address, timeout, loop, builder, reconnect_limit, pack_encoding, unpack_encoding)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout:\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattach_periodic_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages\\msgpackrpc\\loop.py:39\u001b[0m, in \u001b[0;36mLoop.attach_periodic_callback\u001b[1;34m(self, callback, callback_time)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdettach_periodic_callback()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_periodic_callback \u001b[38;5;241m=\u001b[39m ioloop\u001b[38;5;241m.\u001b[39mPeriodicCallback(callback, callback_time, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ioloop)\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_periodic_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages\\tornado\\ioloop.py:899\u001b[0m, in \u001b[0;36mPeriodicCallback.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_loop\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 899\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages\\tornado\\ioloop.py:929\u001b[0m, in \u001b[0;36mPeriodicCallback._schedule_next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_next\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running:\n\u001b[1;32m--> 929\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_next\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_loop\u001b[38;5;241m.\u001b[39madd_timeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_timeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run)\n",
      "File \u001b[1;32mc:\\Users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages\\tornado\\ioloop.py:936\u001b[0m, in \u001b[0;36mPeriodicCallback._update_next\u001b[1;34m(self, current_time)\u001b[0m\n\u001b[0;32m    933\u001b[0m callback_time_sec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_time \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000.0\u001b[39m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjitter:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;66;03m# apply jitter fraction\u001b[39;00m\n\u001b[1;32m--> 936\u001b[0m     callback_time_sec \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjitter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_timeout \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m current_time:\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;66;03m# The period should be measured from the start of one call\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;66;03m# to the start of the next. If one call takes too long,\u001b[39;00m\n\u001b[0;32m    940\u001b[0m     \u001b[38;5;66;03m# skip cycles to get back to a multiple of the original\u001b[39;00m\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# schedule.\u001b[39;00m\n\u001b[0;32m    942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_timeout \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    943\u001b[0m         math\u001b[38;5;241m.\u001b[39mfloor((current_time \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_timeout) \u001b[38;5;241m/\u001b[39m callback_time_sec) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    944\u001b[0m     ) \u001b[38;5;241m*\u001b[39m callback_time_sec\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'AsyncIOLoop' and 'float'"
     ]
    }
   ],
   "source": [
    "env = Env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tornado\n",
      "Version: 4.5.3\n",
      "Summary: Tornado is a Python web framework and asynchronous networking library, originally developed at FriendFeed.\n",
      "Home-page: http://www.tornadoweb.org/\n",
      "Author: Facebook\n",
      "Author-email: python-tornado@googlegroups.com\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: c:\\users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: ipykernel, jupyter_client, msgpack-rpc-python\n"
     ]
    }
   ],
   "source": [
    "!pip show tornado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: airsim 1.8.1\n",
      "Uninstalling airsim-1.8.1:\n",
      "  Successfully uninstalled airsim-1.8.1\n",
      "Collecting airsim\n",
      "  Using cached airsim-1.8.1-py3-none-any.whl\n",
      "Requirement already satisfied: msgpack-rpc-python in c:\\users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages (from airsim) (0.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages (from airsim) (1.24.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages (from airsim) (4.8.1.78)\n",
      "Requirement already satisfied: msgpack-python in c:\\users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages (from msgpack-rpc-python->airsim) (0.5.6)\n",
      "Requirement already satisfied: tornado<5,>=3 in c:\\users\\kaan-\\anaconda3\\envs\\airsim38\\lib\\site-packages (from msgpack-rpc-python->airsim) (4.5.3)\n",
      "Installing collected packages: airsim\n",
      "Successfully installed airsim-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall airsim -y & pip install airsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "# env = gym.make(\"CartPole-v1\")\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (256, 256, 3)\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(INPUT_SHAPE)))\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(actions, activation=\"linear\"))\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model=model,\n",
    "    memory=SequentialMemory(limit=50000, window_length=1),\n",
    "    policy=BoltzmannQPolicy(),\n",
    "    nb_actions=actions,\n",
    "    nb_steps_warmup=10,\n",
    "    target_model_update=0.01\n",
    ")\n",
    "\n",
    "agent.compile(optimizer=Adam(learning_rate=0.001), metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 185s 18ms/step - reward: 1.0000\n",
      "53 episodes - episode_reward: 187.094 [150.000, 248.000] - loss: 3.043 - mae: 27.078 - mean_q: 54.968\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 198s 20ms/step - reward: 1.0000\n",
      "49 episodes - episode_reward: 203.388 [175.000, 261.000] - loss: 3.169 - mae: 39.208 - mean_q: 79.212\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 227s 23ms/step - reward: 1.0000\n",
      "48 episodes - episode_reward: 208.500 [175.000, 238.000] - loss: 2.373 - mae: 39.637 - mean_q: 79.876\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 158s 16ms/step - reward: 1.0000\n",
      "43 episodes - episode_reward: 233.814 [166.000, 500.000] - loss: 1.528 - mae: 37.609 - mean_q: 75.681\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 162s 16ms/step - reward: 1.0000\n",
      "25 episodes - episode_reward: 397.520 [173.000, 500.000] - loss: 7.048 - mae: 42.817 - mean_q: 86.124\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 237s 24ms/step - reward: 1.0000\n",
      "52 episodes - episode_reward: 193.385 [9.000, 330.000] - loss: 22.863 - mae: 60.690 - mean_q: 121.771\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 218s 22ms/step - reward: 1.0000\n",
      "39 episodes - episode_reward: 256.103 [194.000, 500.000] - loss: 8.538 - mae: 62.424 - mean_q: 125.307\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      " 2939/10000 [=======>......................] - ETA: 1:48 - reward: 1.0000done, took 1430.322 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c35b53648>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.fit(env=env, nb_steps=100000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: 500.000, steps: 500\n",
      "Episode 2: reward: 500.000, steps: 500\n",
      "Episode 3: reward: 500.000, steps: 500\n",
      "Episode 4: reward: 500.000, steps: 500\n",
      "Episode 5: reward: 500.000, steps: 500\n",
      "Episode 6: reward: 500.000, steps: 500\n",
      "Episode 7: reward: 500.000, steps: 500\n",
      "Episode 8: reward: 500.000, steps: 500\n",
      "Episode 9: reward: 500.000, steps: 500\n",
      "Episode 10: reward: 500.000, steps: 500\n",
      "500.0\n"
     ]
    }
   ],
   "source": [
    "results = agent.test(env, nb_episodes=10, verbose=1)\n",
    "print(np.mean(results.history[\"episode_reward\"]))\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
