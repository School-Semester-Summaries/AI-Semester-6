{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaan-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\__init__.py:169: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kaan-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kaan-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kaan-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kaan-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tf_agents\\typing\\types.py:114: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments.wrappers import TimeLimit\n",
    "from tf_agents.environments.tf_py_environment import TFPyEnvironment\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import trajectory  # Add this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kaan-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kaan-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tf_agents\\replay_buffers\\tf_uniform_replay_buffer.py:364: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.counter(...)` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kaan-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the environment\n",
    "env_name = 'CartPole-v1'\n",
    "environment = suite_gym.load(env_name)\n",
    "environment = TFPyEnvironment(TimeLimit(environment, duration=1000))\n",
    "\n",
    "# Define the Q-network\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "q_net = q_network.QNetwork(\n",
    "    environment.observation_spec(),\n",
    "    environment.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n",
    "\n",
    "# Define the DQN agent\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-3)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    time_step_spec=environment.time_step_spec(),\n",
    "    action_spec=environment.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()\n",
    "\n",
    "# Define the replay buffer\n",
    "replay_buffer_capacity = 10000\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=environment.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "# Define the data collection\n",
    "collect_steps_per_iteration = 1\n",
    "collect_op = dynamic_step_driver.DynamicStepDriver(\n",
    "    environment,\n",
    "    agent.collect_policy,\n",
    "    observers=[replay_buffer.add_batch],\n",
    "    num_steps=collect_steps_per_iteration).run()\n",
    "\n",
    "# Define the dataset\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=64,\n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "# Define the training\n",
    "num_iterations = 1000\n",
    "batch_size = 32\n",
    "\n",
    "train_op = common.function(agent.train)\n",
    "agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "Replay buffer does not have enough data for training.\n",
      "WARNING:tensorflow:From C:\\Users\\kaan-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "for _ in range(num_iterations):\n",
    "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "    for _ in range(collect_steps_per_iteration):\n",
    "        # Collect data into the replay buffer\n",
    "        time_step = environment.current_time_step()\n",
    "        action_step = agent.collect_policy.action(time_step)\n",
    "        next_time_step = environment.step(action_step.action)\n",
    "        traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "        # Add trajectory to replay buffer\n",
    "        replay_buffer.add_batch(traj)\n",
    "\n",
    "    # Check if the replay buffer has enough data\n",
    "    if replay_buffer.num_frames().numpy() >= batch_size:\n",
    "        # Sample a batch of data from the replay buffer\n",
    "        experience, unused_info = next(iter(dataset))\n",
    "\n",
    "        # Train the agent\n",
    "        train_info = agent.train(experience)\n",
    "\n",
    "        # Print training status\n",
    "        step = agent.train_step_counter.numpy()\n",
    "        if step % 1000 == 0:\n",
    "            print('Step: {}, Loss: {}'.format(step, train_info.loss))\n",
    "    else:\n",
    "        print(\"Replay buffer does not have enough data for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Return: [76.]\n",
      "Episode 2: Total Return: [88.]\n",
      "Episode 3: Total Return: [79.]\n",
      "Episode 4: Total Return: [57.]\n",
      "Episode 5: Total Return: [63.]\n",
      "Episode 6: Total Return: [87.]\n",
      "Episode 7: Total Return: [83.]\n",
      "Episode 8: Total Return: [84.]\n",
      "Episode 9: Total Return: [75.]\n",
      "Episode 10: Total Return: [78.]\n"
     ]
    }
   ],
   "source": [
    "# Test the agent\n",
    "num_episodes = 10  # You can adjust the number of episodes for testing\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "        action_step = agent.policy.action(time_step)\n",
    "        time_step = environment.step(action_step.action)\n",
    "        episode_return += time_step.reward.numpy()\n",
    "\n",
    "    print('Episode {}: Total Return: {}'.format(episode + 1, episode_return))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Return: [64.]\n",
      "Episode 2: Total Return: [63.]\n",
      "Episode 3: Total Return: [78.]\n",
      "closing\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Test the agent with rendering\n",
    "num_episodes = 3\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "        action_step = agent.policy.action(time_step)\n",
    "        time_step = environment.step(action_step.action)\n",
    "        episode_return += time_step.reward.numpy()\n",
    "\n",
    "        # Render the environment\n",
    "        environment.render(mode='human')\n",
    "    print('Episode {}: Total Return: {}'.format(episode + 1, episode_return))\n",
    "\n",
    "print('closing')\n",
    "\n",
    "# Close the environment after testing\n",
    "# environment.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
