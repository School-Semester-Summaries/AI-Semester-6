{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b2138f",
   "metadata": {},
   "source": [
    "# Open Program - Kaan G.\n",
    "In this notebook the code to beat a medium bot is present. It's all the way at the bottom of the notebook. For the rest you will see the steps i took to get there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2c2993",
   "metadata": {},
   "source": [
    "# Chapter 1 - Tracking legends using computer vision\n",
    "Again, we can do this multiple ways. I chose the most simplistic one for now, tracking certain colors on my screen. Inside of the game *Brawlhalla* you can choose a color for your *legend*. This means we can choose a color for our legend that isn't used anywhere else inside of a *match*. this way our *legend* is the only thing being detected by the color detector.\n",
    "\n",
    "Below you will see the slow steps I took to get to color tracking. I also listed certain sources I used per codeblock.\n",
    "\n",
    "**Our end goal of chapter 1 is to have: A color tracker which can detect colors on my own screen, and output the locations of the bounding boxes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5565325",
   "metadata": {},
   "source": [
    "## 1.0 Import Dependencies and check versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # Python 3.10.11\n",
    "import cv2 # 4.6.0\n",
    "import numpy as np # 1.23.4\n",
    "import pyautogui as pg # 0.9.54\n",
    "import PIL\n",
    "from PIL import Image # 9.2.0\n",
    "\n",
    "print(f'Python: {sys.version[0:7]}')\n",
    "print(f'OpenCV2: {cv2.__version__}')\n",
    "print(f'NumPy: {np.__version__}')\n",
    "print(f'PyAutoGUI: {pg.__version__}')\n",
    "print(f'PIL: {PIL.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f1daa",
   "metadata": {},
   "source": [
    "## 1.1 Capture With Laptop Camera or a Video-file and detects moving pixel-areas with an area bigger than 200px\n",
    "Source: https://www.youtube.com/watch?v=GgGro5IV-cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67963cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(\"ML.mp4\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Object Detection from stable camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=40) # might wann aplay with these values for better detection\n",
    "\n",
    "while True:\n",
    "    # Get Frame\n",
    "    ret, frame = cap.read()\n",
    "    height, width, _ = frame.shape\n",
    "    #print(ret)\n",
    "    #print(frame)\n",
    "    #break\n",
    "\n",
    "    # Extract Region of interest\n",
    "    roi = frame[0: 720, 0: 1280] \n",
    "    \n",
    "    # Object Detection\n",
    "    mask = object_detector.apply(roi)\n",
    "    #_, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        # Calculate area and remove small elements\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 200:\n",
    "            #cv2.drawContours(roi, [cnt], -1, (0, 255, 0), 2)\n",
    "            x, y, w, h, = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(roi, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "            print(x, y, w, h)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    \n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5938a12e",
   "metadata": {},
   "source": [
    "## 1.2 Capture With Laptop Cam and point out yellow objects\n",
    "Source: https://youtu.be/aFNDh5k3SjU?si=Uc-dQ_2WLvSLEqxw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6dc8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limits(color):\n",
    "    c = np.uint8([[color]])  # BGR values\n",
    "    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hue = hsvC[0][0][0]  # Get the hue value\n",
    "\n",
    "    # Handle red hue wrap-around\n",
    "    if hue >= 165:  # Upper limit for divided red hue\n",
    "        lowerLimit = np.array([hue - 10, 100, 100], dtype=np.uint8)\n",
    "        upperLimit = np.array([180, 255, 255], dtype=np.uint8)\n",
    "    elif hue <= 15:  # Lower limit for divided red hue\n",
    "        lowerLimit = np.array([0, 100, 100], dtype=np.uint8)\n",
    "        upperLimit = np.array([hue + 10, 255, 255], dtype=np.uint8)\n",
    "    else:\n",
    "        lowerLimit = np.array([hue - 2, 100, 100], dtype=np.uint8)\n",
    "        upperLimit = np.array([hue + 2, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    return lowerLimit, upperLimit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f2df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow = [0, 255, 255]  # yellow in BGR colorspace\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    hsvImage = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lowerLimit, upperLimit = get_limits(color=yellow)\n",
    "\n",
    "    mask = cv2.inRange(hsvImage, lowerLimit, upperLimit)\n",
    "    \n",
    "    mask_ = Image.fromarray(mask)\n",
    "\n",
    "    bbox = mask_.getbbox()\n",
    "\n",
    "    if bbox is not None:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "\n",
    "        frame = cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "        print(f'location: {(x1+x2)/2}, {(y1+y2)/2}')\n",
    "\n",
    "    cv2.imshow('test', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # quit with q\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad05f54",
   "metadata": {},
   "source": [
    "## 1.3 Base code to Capture Screen\n",
    "Finally realised that video capturing screen is nothing different from making screenshots really quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # get frame\n",
    "    screenshot = cv2.cvtColor(np.array(pg.screenshot()), cv2.COLOR_RGB2BGR)\n",
    "    print(screenshot)\n",
    "    \n",
    "    # show frame\n",
    "    cv2.imshow('Screenshot', screenshot)\n",
    "    \n",
    "    # wait 1ms for a key press (for if you want to quit the program)\n",
    "    if cv2.waitKey(1) & 0xFF == 27: break # press escape-key to break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc1f15d",
   "metadata": {},
   "source": [
    "## 1.4 Capture screen and detect pixels\n",
    "Now I can start trying to combine the multiple techniques I have learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3264a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Object Detector\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(\n",
    "    history=100, varThreshold=40)\n",
    "\n",
    "while True:\n",
    "    # get frame\n",
    "    screenshot = cv2.cvtColor(np.array(pg.screenshot()), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Conversion from Screen-reading-code to the other piece of code \n",
    "    frame = screenshot\n",
    "\n",
    "    # read out frame\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Extract Region of interest\n",
    "    roi = frame[0: 720, 0: 1280]\n",
    "\n",
    "    # Object Detection\n",
    "    mask = object_detector.apply(roi)\n",
    "\n",
    "    # Find contours (what are contours ðŸ˜­)\n",
    "    contours, _ = cv2.findContours(\n",
    "        mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Calculate area and remove small elements\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 200:\n",
    "            #cv2.drawContours(roi, [cnt], -1, (0, 255, 0), 2)\n",
    "            x, y, w, h, = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(roi, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "            print(x, y, w, h)\n",
    "\n",
    "\n",
    "\n",
    "    # show frame\n",
    "    cv2.imshow('Screen Capture - Detect Moving Pixels', screenshot)\n",
    "    #cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    # show for a duration of 1ms\n",
    "    if cv2.waitKey(1) & 0xFF == 27: break  # press escape-key to break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1fa2e7",
   "metadata": {},
   "source": [
    "## 1.5 Capture Screen and Track multiple colors\n",
    "Source: https://www.youtube.com/watch?v=ddSo8Nb0mTw&t=290s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a while loop\n",
    "while(True):\n",
    "\n",
    "    screenshot = cv2.cvtColor(np.array(pg.screenshot()), cv2.COLOR_RGB2BGR)\n",
    "    frame = screenshot\n",
    "    # Convert the imageFrame in\n",
    "    # BGR(RGB color space) to\n",
    "    # HSV(hue-saturation-value)\n",
    "    # color space\n",
    "    hsvFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Set range for red color and\n",
    "    # define mask\n",
    "    red_lower = np.array([136, 87, 111], np.uint8)\n",
    "    red_upper = np.array([180, 255, 255], np.uint8)\n",
    "    red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "    # Set range for green color and\n",
    "    # define mask\n",
    "    green_lower = np.array([25, 52, 72], np.uint8)\n",
    "    green_upper = np.array([102, 255, 255], np.uint8)\n",
    "    green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "    # Set range for blue color and\n",
    "    # define mask\n",
    "    blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "    blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "    blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "\n",
    "    # Morphological Transform, Dilation\n",
    "    # for each color and bitwise_and operator\n",
    "    # between imageFrame and mask determines\n",
    "    # to detect only that particular color\n",
    "    kernel = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "    # For red color\n",
    "    red_mask = cv2.dilate(red_mask, kernel)\n",
    "    res_red = cv2.bitwise_and(frame, frame,\n",
    "                              mask=red_mask)\n",
    "\n",
    "    # For green color\n",
    "    green_mask = cv2.dilate(green_mask, kernel)\n",
    "    res_green = cv2.bitwise_and(frame, frame,\n",
    "                                mask=green_mask)\n",
    "\n",
    "    # For blue color\n",
    "    blue_mask = cv2.dilate(blue_mask, kernel)\n",
    "    res_blue = cv2.bitwise_and(frame, frame,\n",
    "                               mask=blue_mask)\n",
    "\n",
    "    # Creating contour to track red color\n",
    "    contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            frame = cv2.rectangle(frame, (x, y),\n",
    "                                       (x + w, y + h),\n",
    "                                       (0, 0, 255), 2)\n",
    "\n",
    "            cv2.putText(frame, \"Red Colour\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                        (0, 0, 255))\n",
    "\n",
    "    # Creating contour to track green color\n",
    "    contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            frame = cv2.rectangle(frame, (x, y),\n",
    "                                       (x + w, y + h),\n",
    "                                       (0, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(frame, \"Green Colour\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.0, (0, 255, 0))\n",
    "\n",
    "    # Creating contour to track blue color\n",
    "    contours, hierarchy = cv2.findContours(blue_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            frame = cv2.rectangle(frame, (x, y),\n",
    "                                       (x + w, y + h),\n",
    "                                       (255, 0, 0), 2)\n",
    "\n",
    "            cv2.putText(frame, \"Blue Colour\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.0, (255, 0, 0))\n",
    "\n",
    "    # Program Termination\n",
    "    cv2.imshow(\"Multiple Color Detection in Real-TIme\", frame)\n",
    "    if cv2.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ff6836",
   "metadata": {},
   "source": [
    "## 1.6 Capture Screen and Detect Jake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07acc851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 1.23.4\n",
    "import pyautogui as pg  # 0.9.54\n",
    "import cv2 # 4.6.0.66\n",
    "\n",
    "\n",
    "# Start a while loop\n",
    "while(True):\n",
    "\n",
    "    screenshot = cv2.cvtColor(np.array(pg.screenshot()), cv2.COLOR_RGB2BGR)\n",
    "    frame = screenshot\n",
    "    # Convert the imageFrame in\n",
    "    # BGR(RGB color space) to\n",
    "    # HSV(hue-saturation-value)\n",
    "    # color space\n",
    "    hsvFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Set range for red color and\n",
    "    # define mask\n",
    "    red_lower = np.array([136, 87, 111], np.uint8)\n",
    "    red_upper = np.array([180, 255, 255], np.uint8)\n",
    "    # jake colors\n",
    "    red_upper = np.array([45, 190, 255], np.uint8)  # B G R\n",
    "    red_lower = np.array([0, 160, 200], np.uint8)\n",
    "    # jake colors\n",
    "    red_upper = np.array([45, 255, 255], np.uint8)  # B G R\n",
    "    red_lower = np.array([0, 175, 200], np.uint8)\n",
    "\n",
    "    red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "    # Morphological Transform, Dilation\n",
    "    # for each color and bitwise_and operator\n",
    "    # between imageFrame and mask determines\n",
    "    # to detect only that particular color\n",
    "    kernel = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "    # For red color\n",
    "    red_mask = cv2.dilate(red_mask, kernel)\n",
    "    res_red = cv2.bitwise_and(frame, frame,\n",
    "                              mask=red_mask)\n",
    "\n",
    "    # Creating contour to track red color\n",
    "    contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            frame = cv2.rectangle(frame, (x, y),\n",
    "                                  (x + w, y + h),\n",
    "                                  (0, 0, 255), 2)\n",
    "\n",
    "            cv2.putText(frame, \"Jake Base\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                        (0, 0, 255))\n",
    "            \n",
    "            print(f'x: {(x+w)/2}, y: {(y+h)/2}') # Extracted Game Variables\n",
    "        else:\n",
    "            print(f'no Jake Base')\n",
    "\n",
    "\n",
    "    # Program Termination\n",
    "    cv2.imshow(\"Jake Detector 2 Pro++ Official\", frame)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32820c5a",
   "metadata": {},
   "source": [
    "## 1.7 Capture Screen and Detect Multiple Jakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35dd356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # 1.23.4\n",
    "import pyautogui as pg  # 0.9.54\n",
    "import cv2  # 4.6.0.66\n",
    "\n",
    "min_area = 2000 # minimum area for pixel-color area to be detected\n",
    "\n",
    "# Start a while loop\n",
    "while(True):\n",
    "\n",
    "    screenshot = cv2.cvtColor(np.array(pg.screenshot()), cv2.COLOR_RGB2BGR)\n",
    "    frame = screenshot\n",
    "    # Convert the imageFrame in\n",
    "    # BGR(RGB color space) to\n",
    "    # HSV(hue-saturation-value)\n",
    "    # color space\n",
    "    hsvFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Set range for red color and\n",
    "    # Red Jake\n",
    "    red_lower = np.array([136, 87, 111], np.uint8)\n",
    "    red_upper = np.array([180, 255, 255], np.uint8)\n",
    "    red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "    # Base Jake (Lightning Yellow)\n",
    "    jake_upper = np.array([45, 255, 255], np.uint8)  # B G R\n",
    "    jake_lower = np.array([0, 175, 200], np.uint8)\n",
    "    jake_mask = cv2.inRange(hsvFrame, jake_lower, jake_upper)\n",
    "    # Blue Jake\n",
    "    blue_lower = np.array([50, 190, 190], np.uint8)\n",
    "    blue_upper = np.array([255, 230, 230], np.uint8)\n",
    "    blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "\n",
    "\n",
    "\n",
    "    # Morphological Transform, Dilation\n",
    "    # for each color and bitwise_and operator\n",
    "    # between imageFrame and mask determines\n",
    "    # to detect only that particular color\n",
    "    kernel = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "    # For red color\n",
    "    jake_mask = cv2.dilate(jake_mask, kernel)\n",
    "    res_jake = cv2.bitwise_and(frame, frame,\n",
    "                              mask=jake_mask)\n",
    "\n",
    "    # # Creating contour to track base jake color\n",
    "    # contours, hierarchy = cv2.findContours(jake_mask,\n",
    "    #                                        cv2.RETR_TREE,\n",
    "    #                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # for pic, contour in enumerate(contours):\n",
    "    #     area = cv2.contourArea(contour)\n",
    "    #     if(area > min_area):\n",
    "    #         x, y, w, h = cv2.boundingRect(contour)\n",
    "    #         frame = cv2.rectangle(frame, (x, y),\n",
    "    #                               (x + w, y + h),\n",
    "    #                               (0, 0, 255), 2)\n",
    "\n",
    "    #         cv2.putText(frame, \"Jake Base\", (x, y),\n",
    "    #                     cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "    #                     (0, 0, 255))\n",
    "\n",
    "    #         print(f'Jake Base - x: {(x+w)/2}, y: {(y+h)/2}')  # Extracted Game Variables\n",
    "    #     else:\n",
    "    #         print(f'no Jake Base')\n",
    "\n",
    "    # For red color\n",
    "    red_mask = cv2.dilate(red_mask, kernel)\n",
    "    res_red = cv2.bitwise_and(frame, frame,\n",
    "                              mask=red_mask)\n",
    "\n",
    "    # Creating contour to track red color\n",
    "    contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > min_area):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            frame = cv2.rectangle(frame, (x, y),\n",
    "                                  (x + w, y + h),\n",
    "                                  (0, 0, 255), 2)\n",
    "\n",
    "            cv2.putText(frame, \"Jake Red\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                        (0, 0, 255))\n",
    "\n",
    "            print(f'Jake Red - x: {(x+w)/2}, y: {(y+h)/2}')  # Extracted Game Variables\n",
    "        else:\n",
    "            print(f'no Jake Red')\n",
    "\n",
    "\n",
    "    # Creating contour to track blue color\n",
    "    contours, hierarchy = cv2.findContours(blue_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            frame = cv2.rectangle(frame, (x, y),\n",
    "                                  (x + w, y + h),\n",
    "                                  (255, 0, 0), 2)\n",
    "\n",
    "            cv2.putText(frame, \"Blue Colour\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.0, (255, 0, 0))\n",
    "            print(f'Jake Blue - x: {(x+w)/2}, y: {(y+h)/2}')\n",
    "        else:\n",
    "            print(f'no Jake Blue')\n",
    "\n",
    "    # Program Termination\n",
    "    cv2.imshow(\"Jake Detector 2 Pro++ Official\", frame)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ceb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygetwindow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e48dd",
   "metadata": {},
   "source": [
    "## 1.9 Controlling Red \"Orion For Hire\" Orion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad087a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e385bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff453e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f9428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356bf22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12662078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d5499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a885ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R 719 72\n",
      "R 690 34\n",
      "R 1061 368\n",
      "R 770 112\n",
      "R 745 74\n",
      "R 810 249\n",
      "R 783 101\n",
      "R 1012 391\n",
      "R 1056 370\n",
      "R 976 394\n",
      "dsig 1115 381\n",
      "R 974 371\n",
      "L 1316 393\n",
      "L 1314 287\n",
      "dsig 1213 398\n",
      "R 1016 131\n",
      "R 1010 344\n",
      "R 980 380\n",
      "dsig 1169 383\n",
      "dsig 1182 382\n",
      "R 1047 394\n",
      "dsig 1187 321\n",
      "dsig 1092 321\n",
      "dsig 1214 375\n",
      "dsig 1199 388\n",
      "dsig 1170 305\n",
      "dsig 1191 323\n",
      "dsig 1193 386\n",
      "dsig 1096 313\n",
      "dsig 1099 344\n",
      "dsig 1104 386\n",
      "dsig 1088 392\n",
      "dsig 1100 383\n",
      "dsig 1088 392\n",
      "dsig 1191 303\n",
      "J 770 561\n",
      "J 779 612\n",
      "J 779 453\n",
      "R 904 178\n",
      "R 936 165\n",
      "R 1025 212\n",
      "L 1436 370\n",
      "J 1539 465\n",
      "J 1486 697\n",
      "J 1435 697\n",
      "J 1490 621\n",
      "L 1512 372\n",
      "L 1507 306\n",
      "L 1443 227\n",
      "L 1435 376\n",
      "L 1437 334\n",
      "R 808 219\n",
      "J 1547 505\n",
      "R 1025 331\n",
      "J 503 872\n",
      "R 701 408\n",
      "R 710 364\n",
      "J 201 568\n",
      "J 215 535\n",
      "R 794 161\n",
      "R 812 116\n",
      "dsig 1139 380\n",
      "L 1368 393\n",
      "L 1302 370\n",
      "dsig 1243 380\n",
      "dsig 1162 330\n",
      "dsig 1157 383\n",
      "R 993 250\n",
      "dsig 1197 380\n",
      "L 1409 395\n",
      "L 1321 371\n",
      "dsig 1210 371\n",
      "dsig 1187 329\n",
      "dsig 1177 388\n",
      "dsig 1194 392\n",
      "dsig 1177 388\n",
      "dsig 1194 392\n",
      "dsig 1268 327\n",
      "dsig 1262 381\n",
      "L 1321 294\n",
      "dsig 1264 315\n",
      "R 1033 35\n",
      "J 774 433\n",
      "J 779 441\n",
      "R 1002 330\n",
      "R 1018 288\n",
      "L 1320 140\n",
      "L 1408 249\n",
      "R 877 0\n",
      "dsig 1145 342\n",
      "dsig 1174 333\n",
      "dsig 1185 386\n",
      "R 901 250\n",
      "L 1304 371\n",
      "L 1410 381\n",
      "dsig 1224 382\n",
      "dsig 1120 383\n",
      "R 896 266\n",
      "R 928 248\n",
      "L 1616 3\n",
      "L 1724 308\n",
      "J 1587 633\n",
      "J 1417 701\n",
      "J 1486 683\n",
      "J 1486 613\n",
      "L 1469 325\n",
      "L 1452 283\n",
      "J 1488 528\n",
      "J 1527 510\n",
      "R 1039 149\n",
      "R 904 381\n",
      "dsig 1093 382\n",
      "dsig 1189 381\n",
      "L 1555 380\n",
      "dsig 1126 371\n",
      "R 987 382\n",
      "R 981 390\n",
      "R 1048 376\n",
      "J 1294 424\n",
      "dsig 1282 369\n",
      "J 1625 531\n",
      "J 1603 500\n",
      "J 1266 833\n",
      "J 1323 786\n",
      "J 1109 893\n",
      "J 971 873\n",
      "J 1121 809\n",
      "J 1094 808\n",
      "J 1147 802\n",
      "J 1070 798\n",
      "J 987 605\n",
      "R 1016 395\n",
      "R 970 105\n",
      "L 1304 392\n",
      "L 1309 380\n",
      "dsig 1119 382\n",
      "R 943 288\n",
      "R 972 270\n",
      "R 982 381\n",
      "dsig 1171 382\n",
      "L 1410 363\n",
      "L 1379 316\n",
      "L 1374 282\n",
      "R 887 368\n",
      "R 813 381\n",
      "R 1007 381\n",
      "R 1008 380\n",
      "dsig 1198 383\n",
      "dsig 1293 381\n",
      "dsig 1290 386\n",
      "R 899 213\n",
      "R 871 204\n",
      "J 1554 716\n",
      "J 1655 435\n",
      "J 742 539\n",
      "dsig 1175 393\n",
      "dsig 1210 381\n",
      "dsig 1197 391\n",
      "R 998 330\n",
      "R 981 288\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Take Screenshot\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(np\u001b[38;5;241m.\u001b[39marray(\u001b[43mpg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreenshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m), cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# convert to hsv for color detecting later\u001b[39;00m\n\u001b[0;32m     38\u001b[0m hsvFrame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyscreeze\\__init__.py:512\u001b[0m, in \u001b[0;36m_screenshot_win32\u001b[1;34m(imageFilename, region)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03mTODO\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# TODO - Use the winapi to get a screenshot, and compare performance with ImageGrab.grab()\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;66;03m# https://stackoverflow.com/a/3586280/1893164\u001b[39;00m\n\u001b[1;32m--> 512\u001b[0m im \u001b[38;5;241m=\u001b[39m \u001b[43mImageGrab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrab\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m region \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(region) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion argument must be a tuple of four ints\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\PIL\\ImageGrab.py:49\u001b[0m, in \u001b[0;36mgrab\u001b[1;34m(bbox, include_layered_windows, all_screens, xdisplay)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     46\u001b[0m     offset, size, data \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mgrabscreen_win32(\n\u001b[0;32m     47\u001b[0m         include_layered_windows, all_screens\n\u001b[0;32m     48\u001b[0m     )\n\u001b[1;32m---> 49\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrombytes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# RGB, 32-bit line padding, origin lower left corner\u001b[39;49;00m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBGR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox:\n\u001b[0;32m     60\u001b[0m         x0, y0 \u001b[38;5;241m=\u001b[39m offset\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\PIL\\Image.py:2809\u001b[0m, in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2805\u001b[0m         color \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mgetcolor(color)\n\u001b[0;32m   2806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m im\u001b[38;5;241m.\u001b[39m_new(core\u001b[38;5;241m.\u001b[39mfill(mode, size, color))\n\u001b[1;32m-> 2809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrombytes\u001b[39m(mode, size, data, decoder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m   2810\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;124;03m    Creates a copy of an image memory from pixel data in a buffer.\u001b[39;00m\n\u001b[0;32m   2812\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m   2831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2833\u001b[0m     _check_size(size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np  # 1.23.4\n",
    "import pyautogui as pg  # 0.9.54\n",
    "import cv2  # 4.6.0.66\n",
    "import time\n",
    "import pygetwindow as gw\n",
    "import win32gui\n",
    "import win32con\n",
    "import random as rnd\n",
    "from modules.movement import move_left_and_attack, move_right_and_attack, jump_to_stage_and_recovery, dsig\n",
    "\n",
    "red_lower = np.array([136, 87, 111], np.uint8) # min red color\n",
    "red_upper = np.array([180, 255, 255], np.uint8) # max red color\n",
    "left = 1080 # left vertical line - decide when to move right or not\n",
    "right = 1300 # right vertical line - decide when to move left or not\n",
    "bottom = 424 # bottom horizontal line - decide when to jump or not\n",
    "top = 300 # top horizontal line - when below top line you can start using dsigs\n",
    "\n",
    "_DOWN_BUTTON = 's'\n",
    "_JUMP_BUTTON = 'space'\n",
    "_LIGHT_BUTTON = 'j'\n",
    "_HEAVY_BUTTON = 'k'\n",
    "_LEFT_BUTTON = 'a'\n",
    "_RIGHT_BUTTON = 'd'\n",
    "\n",
    "time.sleep(2)\n",
    "# pg.press(_JUMP_BUTTON)\n",
    "\n",
    "m=0\n",
    "\n",
    "# Start Bot\n",
    "while(True):\n",
    "    m+=1\n",
    "\n",
    "    # Take Screenshot\n",
    "    frame = cv2.cvtColor(np.array(pg.screenshot()), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # convert to hsv for color detecting later\n",
    "    hsvFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # define mask?\n",
    "    red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "    # Creating contour to track Red color\n",
    "    contours, hierarchy = cv2.findContours(red_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # try to get rid of for loop\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area >= 200):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            frame = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)            \n",
    "            # makes it play as weird as Xefi\n",
    "            pg.keyUp(_DOWN_BUTTON) # reset holding down\n",
    "            if y >= bottom: # jump if too low\n",
    "                jump_to_stage_and_recovery(x, y, left, right)\n",
    "            elif x <= left:\n",
    "                move_right_and_attack(x, y)\n",
    "            elif x >= right:\n",
    "                move_left_and_attack(x, y)\n",
    "            elif y < bottom and y > top: # centered and close to ground\n",
    "                dsig(x, y)\n",
    "\n",
    "    # visualisation (makes app lag)\n",
    "    # cv2.imshow(\"Jake Detector 2 Pro++ Official - (Now also detecting Red Onions)\", frame)\n",
    "    if m == 1000000:\n",
    "        break\n",
    "print(m)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecb0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.5 met imshow\n",
    "# 14.5s voor 200 frames\n",
    "# 1.45s voor 20 frames\n",
    "\n",
    "# 14.3s zonder imshow en frame\n",
    "# 1.43s voor 20 frames\n",
    "\n",
    "# 13.1s met wait key op 1 ipv 5\n",
    "# 1.31s voor 20 framesj\n",
    "\n",
    "# 11s zonder wait key\n",
    "# 1.1s voor 20 frames\n",
    "\n",
    "# 12.2s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
