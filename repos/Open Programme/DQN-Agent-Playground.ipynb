{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.13.0\n",
      "gym: 0.25.2\n",
      "python: 3.8.18 \n",
      "NumPy: 1.24.4\n",
      "keras: 2.10.0\n",
      "keras-rl2: 1.0.5\n",
      "protobuf: 3.20.0\n"
     ]
    }
   ],
   "source": [
    "# env: helpme\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.agents import DQNAgent\n",
    "import rl\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "import time\n",
    "import numpy as np  # 1.24.4\n",
    "import sys  # 3.8.18\n",
    "import random\n",
    "import gym  # 0.25.2\n",
    "import tensorflow  # 2.13.0\n",
    "\n",
    "print(\"tensorflow: \" + tensorflow.__version__) \n",
    "print(\"gym: \" + gym.__version__) \n",
    "print(\"python: \" + sys.version[0:7])\n",
    "print(\"NumPy: \" + np.__version__)\n",
    "print(\"keras: \" + keras.__version__)\n",
    "print(\"keras-rl2: 1.0.5\")\n",
    "print(\"protobuf: 3.20.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"FrozenLake-v1\", render_mode=\"human\")\n",
    "env = gym.make(\"CartPole-v0\", max_episode_steps=5000000000)\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Flatten(input_shape=(1, states)))\n",
    "# model.add(Dense(24, activation='relu'))\n",
    "# model.add(Dense(24, activation='relu'))\n",
    "# model.add(Dense(actions, activation='linear'))\n",
    "\n",
    "\n",
    "# agent = DQNAgent(\n",
    "#     model=model,\n",
    "#     memory=SequentialMemory(limit=50000, window_length=1),\n",
    "#     policy=BoltzmannQPolicy(),\n",
    "#     nb_actions=actions,\n",
    "#     nb_steps_warmup=10,\n",
    "#     target_model_update=0.01\n",
    "# )\n",
    "\n",
    "\n",
    "# agent.compile(optimizer=Adam(learning_rate=0.001), metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 42s 4ms/step - reward: 1.0000\n",
      "46 episodes - episode_reward: 217.000 [148.000, 351.000] - loss: 2.954 - mae: 39.637 - mean_q: 79.962\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 43s 4ms/step - reward: 1.0000\n",
      "41 episodes - episode_reward: 240.073 [185.000, 337.000] - loss: 3.794 - mae: 39.820 - mean_q: 80.136\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 44s 4ms/step - reward: 1.0000\n",
      "31 episodes - episode_reward: 319.290 [235.000, 500.000] - loss: 5.257 - mae: 43.070 - mean_q: 86.623\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 45s 4ms/step - reward: 1.0000\n",
      "49 episodes - episode_reward: 208.000 [113.000, 311.000] - loss: 1.583 - mae: 50.129 - mean_q: 100.995\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 44s 4ms/step - reward: 1.0000\n",
      "36 episodes - episode_reward: 278.889 [189.000, 434.000] - loss: 1.022 - mae: 53.004 - mean_q: 106.627\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 44s 4ms/step - reward: 1.0000\n",
      "28 episodes - episode_reward: 357.893 [202.000, 500.000] - loss: 1.829 - mae: 52.419 - mean_q: 105.216\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 46s 5ms/step - reward: 1.0000\n",
      "26 episodes - episode_reward: 381.346 [269.000, 500.000] - loss: 1.742 - mae: 49.749 - mean_q: 99.791\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 45s 4ms/step - reward: 1.0000\n",
      "27 episodes - episode_reward: 369.593 [302.000, 473.000] - loss: 1.531 - mae: 48.376 - mean_q: 97.013\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "10000/10000 [==============================] - 44s 4ms/step - reward: 1.0000\n",
      "24 episodes - episode_reward: 418.875 [310.000, 500.000] - loss: 1.417 - mae: 46.536 - mean_q: 93.303\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "10000/10000 [==============================] - 44s 4ms/step - reward: 1.0000\n",
      "done, took 440.648 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e9e6c27490>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.fit(env=env, nb_steps=100000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n"
     ]
    }
   ],
   "source": [
    "results = agent.test(env, nb_episodes=10, verbose=1)\n",
    "print(np.mean(results.history[\"episode_reward\"]))\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Wrapper.close of <TimeLimit<OrderEnforcing<StepAPICompatibility<PassiveEnvChecker<CartPoleEnv<CartPole-v0>>>>>>>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helpme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
